{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drinking Water Potability Project\n",
    "\n",
    "**Charles Serve-Catelin** - **Samuel Pujade** - **Mathieu Ract**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération et Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  7 22:05:38 2021 : Warnings Suprimés\n",
      "Sun Nov  7 22:05:38 2021 : Données chargés\n",
      "Sun Nov  7 22:05:38 2021 : Données nulles trouvées\n",
      "Sun Nov  7 22:05:38 2021 : Données nulles supprimées\n",
      "Sun Nov  7 22:05:38 2021 : Données aberrantes gérées\n",
      "Sun Nov  7 22:05:38 2021 : Dataset séparé\n",
      "Sun Nov  7 22:05:38 2021 : Trainset mis à l'echelle\n",
      "Sun Nov  7 22:05:38 2021 : model KNN ajusté\n",
      "Sun Nov  7 22:05:38 2021 : model KNN testé\n",
      "Accuracy KNN : 67.74 %\n",
      "\n",
      "Sun Nov  7 22:05:38 2021 : model LR ajusté\n",
      "Sun Nov  7 22:05:38 2021 : model LR testé\n",
      "Accuracy LR : 60.3 %\n",
      "\n",
      "Sun Nov  7 22:05:38 2021 : model RF ajusté\n",
      "Sun Nov  7 22:05:38 2021 : model RF testé\n",
      "Accuracy RF : 69.23 %\n",
      "\n",
      "Sun Nov  7 22:05:38 2021 : model SVM ajusté\n",
      "Sun Nov  7 22:05:38 2021 : model SVM testé\n",
      "Accuracy SVM : 70.72 %\n",
      "\n",
      "[22:05:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Sun Nov  7 22:05:38 2021 : model XGboost ajusté\n",
      "Sun Nov  7 22:05:38 2021 : model XGboost testé\n",
      "Accuracy XGboost : 66.25 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import project\n",
    "from importlib import reload\n",
    "reload(project)\n",
    "\n",
    "project.avoid_warnings()\n",
    "project.load_data(\"./data/drinking_water_potability.csv\", disp=False)\n",
    "project.display_explanatory_variables(disp=False)\n",
    "project.check_null_values(disp=False)\n",
    "project.cleaning_dataset('delete') # 'mean' or 'delete'\n",
    "project.cope_outliers('Q+1.5') # 'delete' or 'Q+1.5' or 'Q'\n",
    "\n",
    "project.split_dataset(ratio=0.8, disp=False)\n",
    "project.scaling_trainset()\n",
    "project.set_metric('accuracy') # 'accuracy'  or 'f1_score'\n",
    "\n",
    "project.fitting_KNN_model()\n",
    "project.testing_KNN_model()\n",
    "\n",
    "project.fitting_LR_model()\n",
    "project.testing_LR_model()\n",
    "\n",
    "project.fitting_RF_model()\n",
    "project.testing_RF_model()\n",
    "\n",
    "project.fitting_SVM_model()\n",
    "project.testing_SVM_model()\n",
    "\n",
    "project.fitting_XGboost_model()\n",
    "project.testing_XGboost_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning kNN hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a parameter grid to sample from during fitting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  5 17:31:59 2021 : Meilleurs hyperparamètres trouvés                \n",
      "Durée de la recherche : 5.43 secondes\n",
      "Meilleurs Hyperparamètres par méthode RandomizedSearchCV : {'weights': 'distance', 'p': 2, 'n_neighbors': 28, 'leaf_size': 1}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fitsCV ...\n",
      "Fri Nov  5 17:32:37 2021 : Meilleurs hyperparamètres trouvés                \n",
      "Durée de la recherche : 38.39 secondes\n",
      "Meilleurs Hyperparamètres par méthode GridSearchCV : {'leaf_size': 1, 'n_neighbors': 28, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_kNN = {'n_neighbors' : list(range(1, 31)), # Number of neighbors to use\n",
    "    'weights': ['uniform', 'distance'], # Weight function used in prediction\n",
    "    'leaf_size' : list(range(1, 51)), # Leaf size passed to BallTree or KDTree\n",
    "    'p' : [1, 2]} # Power parameter for the Minkowski metric\n",
    "\n",
    "param_grid_kNN_small = {'n_neighbors' : list(range(20, 30)), # Number of neighbors to use\n",
    "    'weights': ['distance'], # Weight function used in prediction\n",
    "    'leaf_size' : list(range(1, 11)), # Leaf size passed to BallTree or KDTree\n",
    "    'p' : [2]} # Power parameter for the Minkowski metric\n",
    "\n",
    "best_params_kNN_RS = project.tuning_kNN_hyperparameters(param_grid_kNN, 'RandomizedSearchCV')\n",
    "best_params_kNN_GS = project.tuning_kNN_hyperparameters(param_grid_kNN_small, 'GridSearchCV')\n",
    "\n",
    "# Temps RandomizedSearchCV (n_iter = 100) : 6s\n",
    "# Params RandomizedSearchCV : {'weights': 'distance', 'p': 2, 'n_neighbors': 28, 'leaf_size': 1}\n",
    "# Accuracy RandomizedSearchCV : 68,37%\n",
    "# Temps GridSearchCV : 36s\n",
    "# Params RandomizedSearchCV : {'weights': 'distance', 'p': 2, 'n_neighbors': 28, 'leaf_size': 1}\n",
    "# Accuracy RandomizedSearchCV : 68,37%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 30 18:07:44 2021 : meilleur model kNN testé et ajusté\n",
      "Accuracy kNN : 68.37 %\n",
      "\n",
      "Sat Oct 30 18:07:44 2021 : meilleur model kNN testé et ajusté\n",
      "Accuracy kNN : 68.37 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project.fitting_kNN_tuned_model(best_params_kNN_RS)\n",
    "project.fitting_kNN_tuned_model(best_params_kNN_GS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Logistic Regression hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a parameter grid to sample from during fitting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 30 19:49:14 2021 : Meilleurs hyperparamètres trouvés                \n",
      "Durée de la recherche : 1.18 secondes\n",
      "Meilleurs Hyperparamètres par méthode RandomizedSearchCV : {'solver': 'newton-cg', 'penalty': 'l2', 'C': 1.0023052380778996}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fitsCV ...\n",
      "Sat Oct 30 19:49:19 2021 : Meilleurs hyperparamètres trouvés                \n",
      "Durée de la recherche : 5.23 secondes\n",
      "Meilleurs Hyperparamètres par méthode GridSearchCV : {'C': 1.0023052380778996, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_LR = {'C': list(range(0.001, 100, 20)),  # penalty strength\n",
    "    'penalty': ['l2'], # Norm of the penalty\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} # Algorithm to use in the optimization problem\n",
    "\n",
    "best_params_LR_RS = project.tuning_LR_hyperparameters(param_grid_LR, 'RandomizedSearchCV')\n",
    "best_params_LR_GS = project.tuning_LR_hyperparameters(param_grid_LR, 'GridSearchCV')\n",
    "\n",
    "# Temps RandomizedSearchCV (n_iter = 100) : 1s\n",
    "# Params RandomizedSearchCV : {'solver': 'newton-cg', 'penalty': 'l2', 'C': 1.0023052380778996}\n",
    "# Accuracy RandomizedSearchCV : 64,38%\n",
    "# Temps GridSearchCV : 5s\n",
    "# Params RandomizedSearchCV : {'solver': 'newton-cg', 'penalty': 'l2', 'C': 1.0023052380778996}\n",
    "# Accuracy RandomizedSearchCV : 64,38%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustement et test du meilleur model LR ...\n",
      "Sat Oct 30 19:49:29 2021 : meilleur model LR testé et ajusté\n",
      "Accuracy LR : 64.38 %\n",
      "\n",
      "Ajustement et test du meilleur model LR ...\n",
      "Sat Oct 30 19:49:29 2021 : meilleur model LR testé et ajusté\n",
      "Accuracy LR : 64.38 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project.fitting_LR_tuned_model(best_params_LR_RS)\n",
    "project.fitting_LR_tuned_model(best_params_LR_GS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning RF hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a parameter grid to sample from during fitting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 220 candidates, totalling 1100 fitsV ...\n",
      "Sun Oct 31 15:16:49 2021 : Meilleurs hyperparamètres trouvés                \n",
      "Durée de la recherche : 6169.54 secondes\n",
      "Meilleurs Hyperparamètres par méthode GridSearchCV : {'bootstrap': True, 'max_depth': 90, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1020}\n"
     ]
    }
   ],
   "source": [
    "param_grid_RF = {'n_estimators' : list(range(200, 2000, 200)), # The number of trees in the forest\n",
    "    'max_depth' : list(range(10, 110, 10)) + [None], # max number of levels in each decision tree\n",
    "    'min_samples_split' : [2, 5, 10], # min number of data points placed in a node before the node is split\n",
    "    'min_samples_leaf' : [1, 2, 4], # min number of data points allowed in a leaf node\n",
    "    'bootstrap' : [True, False]} # method for sampling data points (with or without replacement)\n",
    "\n",
    "param_grid_RF_small = {'n_estimators' : list(range(1000, 1400, 20)), # The number of trees in the forest\n",
    "    'max_depth' : list(range(50, 150, 10)) + [None], # max number of levels in each decision tree\n",
    "    'min_samples_split' : [5], # min number of data points placed in a node before the node is split\n",
    "    'min_samples_leaf' : [4], # min number of data points allowed in a leaf node\n",
    "    'bootstrap' : [True]} # method for sampling data points (with or without replacement)\n",
    "\n",
    "#best_params_RF_RS = project.tuning_RF_hyperparameters(param_grid_RF, 'RandomizedSearchCV')\n",
    "best_params_RF_GS = project.tuning_RF_hyperparameters(param_grid_RF_small, 'GridSearchCV')\n",
    "\n",
    "# Temps RandomizedSearchCV (n_iter = 100) : 915s\n",
    "# Params RandomizedSearchCV : {'n_estimators': 1200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 100, 'bootstrap': True}\n",
    "# Accuracy RandomizedSearchCV : 68,85%\n",
    "# Temps GridSearchCV : 6170s\n",
    "# Params GridSearchCV : {'bootstrap': True, 'max_depth': 90, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 1020}\n",
    "# Accuracy GridSearchCV : 68,21%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 31 15:29:16 2021 : meilleur model RF testé et ajusté\n",
      "Accuracy RF : 68.21 %\n",
      "\n",
      "Sun Oct 31 15:29:21 2021 : meilleur model RF testé et ajusté\n",
      "Accuracy RF : 68.21 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project.fitting_testing_best_RF_model(best_params_RF_RS)\n",
    "project.fitting_testing_best_RF_model(best_params_RF_GS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning SVM hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a parameter grid to sample from during fitting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fitshCV ...\n"
     ]
    }
   ],
   "source": [
    "param_grid_SVM = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], # Kernel type\n",
    "    'C': [0.1, 1, 10, 100], # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "# best_params_SVM_RS = project.tuning_SVM_hyperparameters(param_grid_SVM, 'RandomizedSearchCV')\n",
    "best_params_SVM_GS = project.tuning_SVM_hyperparameters(param_grid_SVM, 'GridSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.fitting_testing_best_SVM_model(best_params_SVM_RS)\n",
    "#project.fitting_testing_best_SVM_model(best_params_SVM_GS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGboost hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify a parameter grid to sample from during fitting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_XGboost = {'min_child_weight': [1, 5, 10],\n",
    "                      'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "                      'subsample': [0.6, 0.8, 1.0],\n",
    "                      'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "                      'max_depth': [3, 4, 5]}\n",
    "\n",
    "best_params_XGboost_GS = project.tuning_XGboost_hyperparameters(param_grid_XGboost, 'GridSearchCV')\n",
    "\n",
    "# Durée de la recherche : 1827.81 secondes\n",
    "# Meilleurs Hyperparamètres par méthode GridSearchCV : {\n",
    "# 'colsample_bytree': 1.0, \n",
    "# 'gamma': 5, \n",
    "# 'max_depth': 5, \n",
    "# 'min_child_weight': 1, \n",
    "# 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Sun Nov  7 21:57:01 2021 : meilleur model XGBoost testé et ajusté\n",
      "Accuracy XGBoost : 63.11 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project.fitting_XGboost_tuned_model(best_params_XGboost_GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f65dd8c84c882f14be6bd1a9d59d5c1e9249b8d074f9b0b9f314a6694312e1be"
  },
  "kernelspec": {
   "display_name": "drinking_water_potability",
   "language": "python",
   "name": "drinking_water_potability"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
